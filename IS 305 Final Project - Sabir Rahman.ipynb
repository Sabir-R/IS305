{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea5ba93",
   "metadata": {},
   "source": [
    "# The Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760811c",
   "metadata": {},
   "source": [
    "## Faculty Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bcacf",
   "metadata": {},
   "source": [
    "This lesson is meant to be an easier one to follow after IS 305. It incorporates the basics of how we learned to read and write out files, specifically csv's for this use case. We use the basics as the example and proceed to explore how to use sqllite3 in python as well. We touched sql a tiny bit in class, and I decided I wanted to explore more, as all I know is that it is a commonly used language when it comes to parsing through databases, which happen to be similar to csv’s. I decided to retrieve my csv’s from a discord bot game called Karuta as it’s a game me and my friends have played over many years, so there would be a lot of data stored, and I can explore many things I want too using sql."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934186f",
   "metadata": {},
   "source": [
    "## Introduction to Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdc20a",
   "metadata": {},
   "source": [
    "Python is a big programming language, with a lot of variety and options for users to accomplish many tasks. You can program some games, process data, use it to make files, make a script for a common task to repeat over and over, all in a simpler language compared to Java or other coding languages. We also have a very huge and diverse amount of modules or packages from the library than can be imported and used for many different tasks.\n",
    "\n",
    "SQL, also known as Structured Query Language is another programming language, however, when compared to other languages like Python, instead of having a large amount of versatility for usage in different scenarios, SQL is made for databases. It allows us to make search queries as well as filter, manage, and modify data being stored in a database. It makes it simple for users to process data and search up anything they want. SQLite 3 is a simpler and friendlier version of SQL. It lets the user utilize SQL on a database they make or import right away, compared to needing a server or some other setup used for normal SQL. It still allows us to use basic query searches and make our own database that can be used for personal projects.\n",
    "\n",
    "The goal for this lesson is to show how we can use python to process data, then proceed to sqlite 3 to make queries and learn more about our data after the cleaning and processing phase. The first goal would be to utilize pathlib, to allow us to access our files, letting us read in data to process. From their, we can clean and choose the data we want overall and proceed to use pathlib to write a new output file, with just the data we want to put into a database. We can then proceed to import sqlite3 and use it and python to convert a csv into a database and explore how to setup and make any queries we want on our database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c8b57",
   "metadata": {},
   "source": [
    "## Core Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083f94a",
   "metadata": {},
   "source": [
    "For this lesson, we will need to be able to use csv, pathlib, and sqlite3. The imports are as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pathlib\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01eb1c",
   "metadata": {},
   "source": [
    "The first thing we need to know is how to read in the csv. This is pretty simple as all we do is use the following template in order to open or read the contents of the file to save the headers and data in our code. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file_name\", \"r\", encoding=\"encoding type\") as infile:\n",
    "    headers, *data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa7245",
   "metadata": {},
   "source": [
    "The r in the code stands for read mode, which allows us to use the reader function in order to save our headers and data in arrays. We define the encoding type for the file to be able to read it in properly, which is usually utf-8. Later on, when we are done cleaning up and saving all the data we want and have our new headers ready, we can use the template again and modify it a bit to write out our new csv file. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file_name.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    csvout = csv.writer(outfile)\n",
    "    csvout.writerow(new_headers)\n",
    "    csvout.writerows(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5358c",
   "metadata": {},
   "source": [
    "The w is for write, and we specify the new_headers and new_data with the corresponding data. The next step would be for us to setup sqlite3. The first thing we do is use pathlib to make a variable to store our new database files we will make. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_target = pathlib.Path('database_name.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940111c",
   "metadata": {},
   "source": [
    "Before we work on making our database file, we should make sure that a file with the same name doesnt already exist. It could exist because we have already tried compiling before and saw that we made it incorrectly, so to make sure it comes out properly, we can use the following code to delete the old file if it exists before making a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb663f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if db_target.exists():\n",
    "    db_target.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee41f6c",
   "metadata": {},
   "source": [
    "Since we are using sqlite3 in python, we need to setup a connection and cursor to be able to execute SQL commands. To do this, we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c872b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_target)\n",
    "\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d061851",
   "metadata": {},
   "source": [
    "Now that we have a cursor setup, we can use the following methods to execute any SQL code we want. The following code has a basic outline of how to make a table and how we can insert data from our csv of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aede767",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"CREATE TABLE table_name (col1 text, col2 integer, col3 date);\")\n",
    "\n",
    "c.executemany(\"INSERT INTO table_name VALUES (?,?,?);\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439cea3",
   "metadata": {},
   "source": [
    "The question marks in the parenthesis after VALUES automatically for each row. We use the execute method when we want to do a single SQL command, such as creating a new table. We use the executemany method when we want to do an SQL command multiple times, such as when we were inserting data from our csv into our database, letting it fill the table in with multiple rows.\n",
    "\n",
    "When we are done creating our table, we can commit the changes and close the connection in order to create our database file. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f60541",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a063f",
   "metadata": {},
   "source": [
    "When we run a query on our database and want to see the results, we use one of the fetch methods in order to get the results and save them to a variable to print out. The three different fetch methods are fetchone, fetchall, and fetchmany. Fetchone returns one row, fetchall would return all the rows, and fetchmany requires a value to return a certain amount of rows that we the user want. An example of this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30725cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT * FROM table;\")\n",
    "\n",
    "result_one = c.fetchone() # returns the first row\n",
    "result_all = c.fetchall() # returns all the rows\n",
    "result_many = c.fetchmay(5) # returns the first five rows\n",
    "\n",
    "# To print out the results\n",
    "\n",
    "print(result_one)\n",
    "\n",
    "for row in result_all: # or result_many\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11fb43",
   "metadata": {},
   "source": [
    "## Small Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be860e33",
   "metadata": {},
   "source": [
    "For this example, lets practice opening up a csv file and selecting only certain headers and data that we want and write out the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48451eab",
   "metadata": {},
   "source": [
    "For starters, lets import csv and use the template to open up one of the provided files to load in the headers and data. For this specific example, I will be using the saber_karuta_collection.csv file. The code for this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684705f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"saber_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    headers, *data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea796a",
   "metadata": {},
   "source": [
    "Now that we have read in our headers and data, we can check that they imported properly or just to see what all the headers are if we have never opened the csv before. The code to check the headers is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a68de8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd9367",
   "metadata": {},
   "source": [
    "To make it easier to see the index value for each column, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d222cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code 0\n",
      "number 1\n",
      "edition 2\n",
      "character 3\n",
      "series 4\n",
      "quality 5\n",
      "obtainedDate 6\n",
      "obtainedTimestamp 7\n",
      "burnValue 8\n",
      "dye.code 9\n",
      "dye.name 10\n",
      "frame 11\n",
      "morphed 12\n",
      "trimmed 13\n",
      "tag 14\n",
      "alias 15\n",
      "wishlists 16\n",
      "fights 17\n",
      "dropQuality 18\n",
      "dropper 19\n",
      "grabber 20\n",
      "guild 21\n",
      "worker.effort 22\n",
      "worker.style 23\n",
      "worker.purity 24\n",
      "worker.grabber 25\n",
      "worker.dropper 26\n",
      "worker.quickness 27\n",
      "worker.toughness 28\n",
      "worker.vanity 29\n",
      "worker.recoveryDate 30\n",
      "worker.recoveryTimestamp 31\n"
     ]
    }
   ],
   "source": [
    "for index, col_name in enumerate(headers):\n",
    "    print(col_name, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7cd6d",
   "metadata": {},
   "source": [
    "We can also check our actual data. We could print out data, but as you can see, it is just the whole csv of data and really hard to read and know where one row starts and one row ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9e17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23959704",
   "metadata": {},
   "source": [
    "To make it easier to go row by row, we can use this code to go row by row, since data is stored as a multidimensional array. This code prints out the whole entire first row(the index is for the first row is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11de4758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2szs16', '58467', '1', 'Charlie', 'Meiji Tokyo Renka Movie: Yumihari no Serenade', '2', 'Fri, 03 Nov 2023 20:50:11 GMT', '1.69904E+12', '5', '', '', '', 'No', 'No', 'burn', '', '1', '0', '2', '480776931629858823', '480776931629858823', '768148469667201054', '1', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e2ea5a",
   "metadata": {},
   "source": [
    "Because the data is saved as a multidimensional array, we can even get a specific column from a specific row. For example, if we want the name of the character in the 5th row, we can use the following code to access that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4541062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enmu\n"
     ]
    }
   ],
   "source": [
    "print(data[4][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaada06",
   "metadata": {},
   "source": [
    "Just to double check this is correct..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c10b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2dlslx', '14458', '3', 'Enmu', 'Demon Slayer: Kimetsu no Yaiba', '2', 'Thu, 02 Nov 2023 18:31:25 GMT', '1.69895E+12', '84', '', '', '', 'No', 'No', 'burn', '', '114', '0', '2', '480776931629858823', '480776931629858823', '768148469667201054', '44', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9fa3a",
   "metadata": {},
   "source": [
    "Now that we know how to access our data, the next step is to figure out what columns of data we want. For this example, lets just grab the card code, the print number of the card, what edition the card is, the name of the character on the card, the series the character on the card is from, the current quality of the card, the wishlist number of the card(also known as how many people want that specific character), and the quality the card originally dropped in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc18ac",
   "metadata": {},
   "source": [
    "To do this, we can make an array to store the index values of the specific columns of data that we want in our new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc7dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values = [0, 1, 2, 3, 4, 5, 16, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b98344",
   "metadata": {},
   "source": [
    "Now, we can make our new header array for the final csv file that we will make at the end. To do this, we can make an empty array to store the new headers and loop through our index_values and append to our new headers array the corresponding index value from the original headers array we read in. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd08685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'wishlists', 'dropQuality']\n"
     ]
    }
   ],
   "source": [
    "new_headers = []\n",
    "\n",
    "for i in index_values:\n",
    "    new_headers.append(headers[i])\n",
    "    \n",
    "print(new_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14730c52",
   "metadata": {},
   "source": [
    "Next, we want to make a new array to store the new data that will contain the data from each column for every row. To do this, we can loop through the data, tracking the index and row of each row of data, make a temporary array to store the new row, and use another for loop inside to get the specific columns of data we want for each row to append into our new data array. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fa811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2dlslx', '14458', '3', 'Enmu', 'Demon Slayer: Kimetsu no Yaiba', '2', '114', '2']\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "\n",
    "for index, row in enumerate(data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)\n",
    "\n",
    "print(new_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00ef96",
   "metadata": {},
   "source": [
    "Now that we have our new headers and data, all we have to do is use the template to create our new csv with the data that we want to use. I will be saving the new csv as example1.csv. The code to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871672da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example1.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    csvout = csv.writer(outfile)\n",
    "    csvout.writerow(new_headers)\n",
    "    csvout.writerows(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a21119",
   "metadata": {},
   "source": [
    "Now if we check the directory we are working in, we will see a new csv file that has just the data we wanted. We can use this csv for our next example to practice some SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd713f",
   "metadata": {},
   "source": [
    "## Small Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b74ed3",
   "metadata": {},
   "source": [
    "For this example, lets use the csv we made in the previous example to practice using SQLite3 and make a new database with a table and import the data from that csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa429fb",
   "metadata": {},
   "source": [
    "For starters, lets import csv, sqlite3, and pathlib so that we can read in our csv file and set up the new database file we will be working with. Don't forget to include the code shown previously, so that if you mess up and want to recreate the file later, it will delete the old one before making a new one. I will name the database file as example2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b3be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import pathlib\n",
    "\n",
    "with open(\"example1.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    headers, *data = csv.reader(infile)\n",
    "\n",
    "db_example = pathlib.Path('example2.db')\n",
    "\n",
    "if db_example.exists():\n",
    "    db_example.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c445d11",
   "metadata": {},
   "source": [
    "Next, we need to make sure we set up the connection and cursor so that we will be able to execute our SQL code inside of python. The code for this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf28c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_example)\n",
    "\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d7795",
   "metadata": {},
   "source": [
    "Now that we have everything set up, we need to create a table in SQL to hold our data. Let's name the table example2 and set it up to have the column names be the same as our headers. We have to make sure to specify the type of data that will be contained in these columns. Another thing to notice is that we should also include the phrase IF NOT EXISTS while creating the table. If we run our code to make the table for the first time, it would work just fine. But if we try to run the code again later, it will throw an error as the table already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf3c46",
   "metadata": {},
   "source": [
    "To check our headers to make sure they are accurate in our SQL table to import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32b4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'wishlists', 'dropQuality']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d01977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062ac840>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"CREATE TABLE IF NOT EXISTS example2 (code text, number integer, edition integer, character text, series text, quality integer, wishlists integer, dropQuality integer);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73fcf8",
   "metadata": {},
   "source": [
    "In case you mess up the creation of the table, you can't just change the original code to create the table. You would have to delete the table entirely and then recreate the table. The code to do this is the following, and you could just have it before creating the table so that you are always creating the table fresh every time you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14001a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062ac840>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"DROP TABLE IF EXISTS example2\")\n",
    "\n",
    "c.execute(\"CREATE TABLE IF NOT EXISTS example2 (code text, number integer, edition integer, character text, series text, quality integer, wishlists integer, dropQuality integer);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a4f69",
   "metadata": {},
   "source": [
    "Once you have the table created properly, the next step is to populate the table with the data from our csv. To do this is actually very simple, as SQLite3 is able to handle the data input very easily. Remember to use executemany since we are inserting multiple rows of data. We put 8 question marks as we have 8 columns of data per row. The code to do so is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e2cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062ac840>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.executemany(\"INSERT INTO example2 VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201674d",
   "metadata": {},
   "source": [
    "Congratulations, you have successfully created your own database with a table filled with data from a csv you imported. Unfortunately, if you try to open up the database file after running all the previous code, you will just see an empty table created with the column names but no data. This is because even though we ran the code to insert the data from the csv into the table, we did not actually commit the changes to save the data inside of our table. The code that we need to do so is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea06a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46492be4",
   "metadata": {},
   "source": [
    "Don't forget to close the connection since we are done now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b095e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004f78c",
   "metadata": {},
   "source": [
    "## The Final Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538f7f6",
   "metadata": {},
   "source": [
    "For this final problem, we will take multiple csv's with similar data from different people that have played the card collecting game Karuta. We will extract the data that we want specifically from each person, and add a column to the final csv so that we know who owns that card. We will then follow up by creating a database file using SQL so that we can run different queries to compare the collections. We will have a master table with everyone's card collection data available, as well as make separate tables for each card collection so that we can run certain queries on all the tables to compare results of overall versus individual player preferences or statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc42b2",
   "metadata": {},
   "source": [
    "First, let's import all our packages needed and open up the csv files with all our players collections data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258e7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dd309e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saber_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    saber_headers, *saber_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf715e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"matt_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    matt_headers, *matt_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea7e4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gerald_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    gerald_headers, *gerald_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8a3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"forming_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    forming_headers, *forming_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b25e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cher_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    cher_headers, *cher_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e2c8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"boof_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    boof_headers, *boof_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d96b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"black_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    black_headers, *black_data = csv.reader(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931faed",
   "metadata": {},
   "source": [
    "Before proceeding to choose the data we want for our database, lets add an extra column so that we know which person owns the card in their collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea70bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saber_headers.append(\"owner\")\n",
    "\n",
    "for row in saber_data:\n",
    "    row.append(\"saber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e435d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matt_headers.append(\"owner\")\n",
    "\n",
    "for row in matt_data:\n",
    "    row.append(\"matt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77151af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerald_headers.append(\"owner\")\n",
    "\n",
    "for row in gerald_data:\n",
    "    row.append(\"gerald\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "707da6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forming_headers.append(\"owner\")\n",
    "\n",
    "for row in forming_data:\n",
    "    row.append(\"forming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61cab200",
   "metadata": {},
   "outputs": [],
   "source": [
    "cher_headers.append(\"owner\")\n",
    "\n",
    "for row in cher_data:\n",
    "    row.append(\"cher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd8eb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boof_headers.append(\"owner\")\n",
    "\n",
    "for row in boof_data:\n",
    "    row.append(\"boof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0ff37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_headers.append(\"owner\")\n",
    "\n",
    "for row in black_data:\n",
    "    row.append(\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226123fb",
   "metadata": {},
   "source": [
    "Just to check we properly added the new column and proper row, we can quickly print out the headers for each person and check the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8997b9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(saber_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "989008f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2szs16', '58467', '1', 'Charlie', 'Meiji Tokyo Renka Movie: Yumihari no Serenade', '2', 'Fri, 03 Nov 2023 20:50:11 GMT', '1.69904E+12', '5', '', '', '', 'No', 'No', 'burn', '', '1', '0', '2', '480776931629858823', '480776931629858823', '768148469667201054', '1', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '', 'saber']\n"
     ]
    }
   ],
   "source": [
    "print(saber_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c35d953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(matt_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22ac5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v26qz15', '795', '4', 'Muderev', 'The Reincarnation of the Strongest Exorcist in Another World', '4', 'Mon, 06 Nov 2023 03:11:03 GMT', '1699240263663', '160', '', '', '', 'No', 'No', '', '', '1', '0', '4', '289730004600750081', '289730004600750081', '768148469667201054', '85', 'F', 'S', 'S', 'S', 'A', 'F', 'F', '', '', 'matt']\n"
     ]
    }
   ],
   "source": [
    "print(matt_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aa3de52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(gerald_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e4bedea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vw86sxs', '60093', '1', 'Hotaru Rindou', 'Qualidea Code', '0', 'Wed, 13 Dec 2023 22:32:18 GMT', '1702506738294', '1', '', '', '', 'No', 'No', '', '', '1', '0', '0', '632803583586205729', '632803583586205729', '768148469667201054', '0', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '', 'gerald']\n"
     ]
    }
   ],
   "source": [
    "print(gerald_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d95e7cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(forming_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "878b82ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2dqnmq', '13635', '3', 'Megumi Fushiguro', 'Jujutsu Kaisen', '1', 'Wed, 01 Nov 2023 20:06:54 GMT', '1698869214710', '44', '', '', '', 'No', 'No', '', '', '2577', '0', '1', '404127890649907204', '226504477161684993', '730537558911484028', '23', 'F', 'S', 'S', 'F', 'S', 'F', 'D', '', '', 'forming']\n"
     ]
    }
   ],
   "source": [
    "print(forming_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3886926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(cher_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5dcee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vq8f4tf', '55624', '1', 'Abdul Hakim', 'Cowboy Bebop', '2', 'Sat, 29 Jul 2023 00:10:59 GMT', '1690589459958', '7', '', '', '', 'No', 'No', 'kobe', '', '1', '0', '2', '393131628827770890', '393131628827770890', '730537558911484028', '4', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '', 'cher']\n"
     ]
    }
   ],
   "source": [
    "print(cher_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd767315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(boof_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24151f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v276hz5', '8438', '4', 'Houshou Marine', 'Hololive: Holo no Graffiti', '4', 'Wed, 01 Nov 2023 16:13:49 GMT', '1.69886E+12', '324', '', '', '', 'No', 'No', '', '', '397', '0', '4', '2.47132E+17', '2.47132E+17', '3.43119E+17', '176', 'F', 'S', 'S', 'S', 'S', 'F', 'D', '', '', 'boof']\n"
     ]
    }
   ],
   "source": [
    "print(boof_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd5a7ef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'obtainedDate', 'obtainedTimestamp', 'burnValue', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'tag', 'alias', 'wishlists', 'fights', 'dropQuality', 'dropper', 'grabber', 'guild', 'worker.effort', 'worker.style', 'worker.purity', 'worker.grabber', 'worker.dropper', 'worker.quickness', 'worker.toughness', 'worker.vanity', 'worker.recoveryDate', 'worker.recoveryTimestamp', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(black_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5161bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2866pv', '3011', '2', 'Bruno Bradley', 'The Iceblade Sorcerer Shall Rule the World', '3', 'Sun, 29 Oct 2023 17:46:25 GMT', '1698601585461', '46', '', '', '', 'No', 'No', '', '', '0', '0', '3', '190147150485651457', '190147150485651457', '745688976014180493', '25', 'F', 'S', 'S', 'S', 'A', 'F', 'D', '', '', 'black']\n"
     ]
    }
   ],
   "source": [
    "print(black_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8ba0e",
   "metadata": {},
   "source": [
    "Now we need to determine what data to collect. Since I want to compare different player preferences and statistics, we can collect data that matters in the game, such as worker quality values, the total wishlist collected (can be used to show as an indicator of how big of a collector a player is), and how much a card has been customized(looking at cosmetics such as if a card has been dyed, framed, morphed, trimmed, or given an alias). Let's save our header's in an array called new_headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f183213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code 0\n",
      "number 1\n",
      "edition 2\n",
      "character 3\n",
      "series 4\n",
      "quality 5\n",
      "obtainedDate 6\n",
      "obtainedTimestamp 7\n",
      "burnValue 8\n",
      "dye.code 9\n",
      "dye.name 10\n",
      "frame 11\n",
      "morphed 12\n",
      "trimmed 13\n",
      "tag 14\n",
      "alias 15\n",
      "wishlists 16\n",
      "fights 17\n",
      "dropQuality 18\n",
      "dropper 19\n",
      "grabber 20\n",
      "guild 21\n",
      "worker.effort 22\n",
      "worker.style 23\n",
      "worker.purity 24\n",
      "worker.grabber 25\n",
      "worker.dropper 26\n",
      "worker.quickness 27\n",
      "worker.toughness 28\n",
      "worker.vanity 29\n",
      "worker.recoveryDate 30\n",
      "worker.recoveryTimestamp 31\n",
      "owner 32\n"
     ]
    }
   ],
   "source": [
    "for index, col_name in enumerate(saber_headers):\n",
    "    print(col_name, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2231792",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values = [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 15, 16, 18, 22, 23, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59c62c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'alias', 'wishlists', 'dropQuality', 'worker.effort', 'worker.style', 'owner']\n"
     ]
    }
   ],
   "source": [
    "new_headers = []\n",
    "\n",
    "for i in index_values:\n",
    "    new_headers.append(saber_headers[i])\n",
    "    \n",
    "print(new_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322ef3c",
   "metadata": {},
   "source": [
    "Great! Now that we have our headers selected for our csv file, we need to grab the data from each csv and put it into our final data array as well. Let's call our final array new_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a5e4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25df716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(saber_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f4142a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(matt_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "581928df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(gerald_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4973ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(forming_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14da508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(cher_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b65e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(boof_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97b119ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(black_data):\n",
    "    new_row = []\n",
    "    for i in index_values:\n",
    "        new_row.append(row[i])\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3797c",
   "metadata": {},
   "source": [
    "Now lets check to make sure we have all the data collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66a35298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18950\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e934474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2szs16', '58467', '1', 'Charlie', 'Meiji Tokyo Renka Movie: Yumihari no Serenade', '2', '', '', '', 'No', 'No', '', '1', '2', '1', 'F', 'saber']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad618742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q8hfmb', '6750', '1', 'Suzuki', 'Mayoi Neko Overrun!', '2', '', '', '', 'No', 'No', '', '0', '2', '1', 'F', 'matt']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2acf5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nvmb3r', '334', '2', 'Sherry Polnareff', \"JoJo's Bizarre Adventure: Stardust Crusaders\", '2', '', '', '', 'No', 'No', '', '1', '2', '25', 'F', 'gerald']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab496be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clt8w6', '824', '2', 'Rick Dias', 'Mobile Suit Zeta Gundam', '2', '', '', '', 'No', 'No', '', '3', '2', '15', 'F', 'forming']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bab19723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vm6bm5f', '1914', '3', 'Riho Sasaki', 'The Devil Is a Part-Timer!', '4', '', '', '', 'No', 'No', '', '1', '4', '76', 'F', 'cher']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea712bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13thcn', '995', '3', 'Haruhime Sanjouno', 'Is It Wrong to Try to Pick Up Girls in a Dungeon? II', '3', '', '', '', 'No', 'No', '', '21', '3', '70', 'F', 'black']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3988b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vbbkdk', '2355', '1', 'Semiramis', 'Fate/Apocrypha', '2', '', '', '', 'No', 'No', '', '35', '2', '23', 'F', 'black']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[18750])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e5c76",
   "metadata": {},
   "source": [
    "As we can see, we have all the data, but some columns have blank or empty data values. Let's replace these empty values as None so that when we import our csv into our table, it will become null in SQLite3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe595cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in new_data:\n",
    "    if row[6] == '':\n",
    "        row[6] = None\n",
    "        \n",
    "    if row[7] == '':\n",
    "        row[7] = None\n",
    "        \n",
    "    if row[8] == '':\n",
    "        row[8] = None\n",
    "        \n",
    "    if row[11] == '':\n",
    "        row[11] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2a3ac4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2szs16', '58467', '1', 'Charlie', 'Meiji Tokyo Renka Movie: Yumihari no Serenade', '2', None, None, None, 'No', 'No', None, '1', '2', '1', 'F', 'saber']\n"
     ]
    }
   ],
   "source": [
    "print(new_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d57f07",
   "metadata": {},
   "source": [
    "Great! Now we have all our empty values set to None. The final step for this part is to create our final csv file. Let's call this new file master_karuta_collection.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bb59e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"master_karuta_collection.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    csvout = csv.writer(outfile)\n",
    "    csvout.writerow(new_headers)\n",
    "    csvout.writerows(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d68246",
   "metadata": {},
   "source": [
    "Now that we have our master csv file with the data we want, the next step is to start using SQLite3. Lets open up our csv file and create our master database file as master.db. Don't forget to setup the connection and cursor so we can use the SQL commands and save our table and changes when we are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a4a6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"master_karuta_collection.csv\", \"r\", encoding='utf-8') as infile:\n",
    "    headers, *data = csv.reader(infile)\n",
    "\n",
    "db_master = pathlib.Path('master.db')\n",
    "\n",
    "if db_master.exists():\n",
    "    db_master.unlink()\n",
    "    \n",
    "conn = sqlite3.connect(db_master)\n",
    "\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c8ee8",
   "metadata": {},
   "source": [
    "Let's check our headers and create our master table in our database. Make sure to use execute for creating the table and executemany when importing the data. I will be renaming number as print_number, character as character_name, dye.code as dye_code, dye.name as dye_name, alias as nickname, wishlists as wishlist_count, worker.effort as workEffort, and worker.style as workerStyle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb0ddcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'number', 'edition', 'character', 'series', 'quality', 'dye.code', 'dye.name', 'frame', 'morphed', 'trimmed', 'alias', 'wishlists', 'dropQuality', 'worker.effort', 'worker.style', 'owner']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d14cdfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"DROP TABLE IF EXISTS master\")\n",
    "\n",
    "c.execute(\"CREATE TABLE IF NOT EXISTS master (code text, print_number integer, edition integer, character_name text, series text, quality integer, dye_code text, dye_name text, frame text, morphed text, trimmed text, nickname text, wishlist_count integer, dropQuality integer, workEffort integer, workerStyle text, owner text);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7101e88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.executemany(\"INSERT INTO master VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a820b5",
   "metadata": {},
   "source": [
    "Make sure to commit so that you can open up the table and check that the table is created properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76cbf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c04313",
   "metadata": {},
   "source": [
    "To actually check our data in python, we can use the following code to retrieve each row of data and print it out in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d78af7f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.execute(\"SELECT * FROM master\")\n",
    "\n",
    "master_table = c.fetchall()\n",
    "\n",
    "# print(master_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca28f10",
   "metadata": {},
   "source": [
    "Since we have empty values still that aren't showing up as null, we can use SQL to change them into null with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a2b030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"UPDATE master SET dye_code = NULL WHERE dye_code = '';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f5bc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"UPDATE master SET dye_name = NULL WHERE dye_name = '';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4e801e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"UPDATE master SET frame = NULL WHERE frame = '';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0b4115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"UPDATE master SET nickname = NULL WHERE nickname = '';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd1ca251",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38814abc",
   "metadata": {},
   "source": [
    "Now when we print out the table again, we should see the empty values replaced with NULL values in the database, or None for Python's case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d3f0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT * FROM master;\")\n",
    "\n",
    "master_table = c.fetchall()\n",
    "\n",
    "# print(master_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755db03",
   "metadata": {},
   "source": [
    "Since we have our master table set up, we can start making comparisons using different search queries. Before we do that however, I will show how we can split up our master table into smaller tables that contain the info for each owner, basically reversing the process of where we combined multiple csv's into one, this time in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0d4c30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"DROP TABLE IF EXISTS saber\")\n",
    "\n",
    "c.execute(\"CREATE TABLE saber AS SELECT * FROM master WHERE owner = 'saber';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a52eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f997f",
   "metadata": {},
   "source": [
    "We can check if it worked by printing the new table and making sure the only value for owner is saber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d82c6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT * FROM saber;\")\n",
    "\n",
    "saber_table = c.fetchall()\n",
    "\n",
    "# print(saber_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a2476",
   "metadata": {},
   "source": [
    "Since it has, we can finish creating the smaller tables for the other players as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba511e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1062af640>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"DROP TABLE IF EXISTS matt\")\n",
    "c.execute(\"CREATE TABLE matt AS SELECT * FROM master WHERE owner = 'matt';\")\n",
    "\n",
    "c.execute(\"DROP TABLE IF EXISTS gerald\")\n",
    "c.execute(\"CREATE TABLE gerald AS SELECT * FROM master WHERE owner = 'gerald';\")\n",
    "\n",
    "c.execute(\"DROP TABLE IF EXISTS forming\")\n",
    "c.execute(\"CREATE TABLE forming AS SELECT * FROM master WHERE owner = 'forming';\")\n",
    "\n",
    "c.execute(\"DROP TABLE IF EXISTS cher\")\n",
    "c.execute(\"CREATE TABLE cher AS SELECT * FROM master WHERE owner = 'cher';\")\n",
    "\n",
    "c.execute(\"DROP TABLE IF EXISTS boof\")\n",
    "c.execute(\"CREATE TABLE boof AS SELECT * FROM master WHERE owner = 'boof';\")\n",
    "\n",
    "c.execute(\"DROP TABLE IF EXISTS black\")\n",
    "c.execute(\"CREATE TABLE black AS SELECT * FROM master WHERE owner = 'black';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "514d10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c50c71",
   "metadata": {},
   "source": [
    "Now that we have our master table and smaller tables, we are done with the data cleaning and processing. We can now have fun and explore any queries we want to compare and contrast each player to each other and to the whole dataset as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0af33",
   "metadata": {},
   "source": [
    "The best part of this problem is that we can use sql to make simple search queries and save the results to print out in python instead of doing complicated loops to try and filter data ourselves inside of python. For starters, let's compare everyone's collection size, to see who the largest hoarder is. We can make an array of player names and array to store our query results so it's easy to loop and print out our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54c6fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = ['saber', 'matt', 'gerald', 'forming', 'cher', 'boof', 'black']\n",
    "players_collection_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c485b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from saber;\")\n",
    "\n",
    "saber_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(saber_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1feb15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from matt;\")\n",
    "\n",
    "matt_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(matt_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7fb6625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from gerald;\")\n",
    "\n",
    "gerald_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(gerald_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57a2d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from forming;\")\n",
    "\n",
    "forming_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(forming_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b74b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from cher;\")\n",
    "\n",
    "cher_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(cher_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cb1ca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from boof;\")\n",
    "\n",
    "boof_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(boof_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5b529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT COUNT(*) from black;\")\n",
    "\n",
    "black_collection_size = c.fetchone()\n",
    "\n",
    "players_collection_sizes.append(black_collection_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a66c0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saber has a collection size of 3962\n",
      "matt has a collection size of 1485\n",
      "gerald has a collection size of 2066\n",
      "forming has a collection size of 3441\n",
      "cher has a collection size of 1941\n",
      "boof has a collection size of 272\n",
      "black has a collection size of 5783\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(players)):\n",
    "    print(players[i], \"has a collection size of\", players_collection_sizes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb7bf0",
   "metadata": {},
   "source": [
    "As we can see, boof has the smallest collection size of 272, whereas black has the largest collection size of 5782. Now lets check out who has the highest valued collection in terms of wishlist total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "212b7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_wishlists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e47f1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from saber;\")\n",
    "\n",
    "saber_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(saber_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f2a92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from matt;\")\n",
    "\n",
    "matt_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(matt_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fd3f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from gerald;\")\n",
    "\n",
    "gerald_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(gerald_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "382f6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from forming;\")\n",
    "\n",
    "forming_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(forming_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f8c3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from cher;\")\n",
    "\n",
    "cher_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(cher_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5384a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from boof;\")\n",
    "\n",
    "boof_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(boof_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fba10682",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT SUM(wishlist_count) from black;\")\n",
    "\n",
    "black_wishlist = c.fetchone()\n",
    "\n",
    "player_wishlists.append(black_wishlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7cb960dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saber has a collection wishlist total of 524644\n",
      "matt has a collection wishlist total of 45752\n",
      "gerald has a collection wishlist total of 65388\n",
      "forming has a collection wishlist total of 410193\n",
      "cher has a collection wishlist total of 191192\n",
      "boof has a collection wishlist total of 29209\n",
      "black has a collection wishlist total of 671151\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(players)):\n",
    "    print(players[i], \"has a collection wishlist total of\", player_wishlists[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f06ed4",
   "metadata": {},
   "source": [
    "We can see similar results once more with black having the highest amount of wishlist cards in his collection compared to boof having the least wishlist in their collection. However, something to consider would be the number of cards someone has, to see if they have a higher wl average per card, as that could mean they actually have cards that are worth more per wishlist. Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ddc09937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saber has an average wishlist value per card of 0.007551787497808038\n",
      "matt has an average wishlist value per card of 0.032457597482077286\n",
      "gerald has an average wishlist value per card of 0.031596011500581146\n",
      "forming has an average wishlist value per card of 0.008388734083711814\n",
      "cher has an average wishlist value per card of 0.010152098414159589\n",
      "boof has an average wishlist value per card of 0.009312198295046047\n",
      "black has an average wishlist value per card of 0.008616540838052838\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(players)):\n",
    "    print(players[i], \"has an average wishlist value per card of\", (players_collection_sizes[i]/player_wishlists[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee764a",
   "metadata": {},
   "source": [
    "This result shows a completly different result, with Matt actually having the highest wishlist average per card and saber having the least."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb41d1",
   "metadata": {},
   "source": [
    "Another thing we can check easily using SQL is who has the most customized card. This would mean that a card has a quality of 4(the best quality possible), a dye code, a dye name, a frame, is morphed, is trimmed, and has a nickname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e5df961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('h6llcd', 998, 2, \"Jeanne d'Arc (Alter)\", 'Fate/Grand Order', 4, '$jwlhd', 'Mystic Girls Night Out', 'blacktiara', 'Yes', 'Yes', 'The Dragon Witch', 366, 3, 350, 'S', 'saber')]\n"
     ]
    }
   ],
   "source": [
    "c.execute(\"SELECT * from master where quality = 4 AND dye_code is not NULL and dye_name is not NULL and frame is not NULL and morphed = 'Yes' and trimmed = 'Yes' AND nickname is not NULL;\")\n",
    "maxed_cards = c.fetchall()\n",
    "print(maxed_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12907a02",
   "metadata": {},
   "source": [
    "Surprisingly, there is only 1 card out of the 18950 cards in the data that is fully maxed out in terms of customization. This shows that players definetly don't prefer to max out cards, which could be due to the investment required to fully max out a card. We can check this by checking what most player's consider a decent card, that being having a quality of 4, dye code, dye name, and a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df150be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT * from master where quality = 4 AND dye_code is not NULL and dye_name is not NULL and frame is not NULL;\")\n",
    "decent_cards = c.fetchall()\n",
    "# print(decent_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41806a",
   "metadata": {},
   "source": [
    "There is definitely a lot more cards customized but not fully. Let's see how many in total and the amount from each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4552e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "c.execute(\"SELECT COUNT(*) from master where quality = 4 AND dye_code is not NULL and dye_name is not NULL and frame is not NULL;\")\n",
    "total_decent_cards = c.fetchall()\n",
    "print(total_decent_cards[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae8cf4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('saber', 79), ('black', 54), ('cher', 29), ('forming', 26), ('boof', 3)]\n"
     ]
    }
   ],
   "source": [
    "c.execute(\"SELECT owner, COUNT(*) as total from master where quality = 4 AND dye_code is not NULL and dye_name is not NULL and frame is not NULL GROUP by owner order by total DESC;\")\n",
    "player_decent_cards = c.fetchall()\n",
    "print(player_decent_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8d579",
   "metadata": {},
   "source": [
    "Here we can find a more detailed break down on how many decently customized cards each player has. The query allowed me to order the results in descending order so we can see who has the most first to the least last. We see that Matt and Gerald are missing from the query results, meaning that they have 0 decent cards at all. This could be viewed as them being purely collector players or casual players, that don't care much for the showing off of cards other than the fact that they have one, even if it is uncustomized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d110c",
   "metadata": {},
   "source": [
    "Overall, this final problem has allowed us to explore how to combine multiple csv's into one and load it into SQL. We were able to clean and process the data that we wanted and load it into a table for further investigation. We also learned how to break down a huge table into smaller, more categorized table, in our case being for each player. This could easily have been done since we have the csv files for each individual, but in the case we only had a master csv, this is useful to know to help look at a target person in our case. Finally, we were able to do some sample queries to analyze and see the difference in player collection's and their choice on how they customize their cards, being fully customized, decently customized, or not at all. There are definitely a lot more queries that can be done, and I encourage you all to try and make your own from the SQL you have learned here and more you can learn online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2ea37",
   "metadata": {},
   "source": [
    "Oh, and don't forget to commit and close your connection once you are done! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "22673a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
